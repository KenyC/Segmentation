import pickle
import numpy as np
from scipy import stats
from math import sqrt
import MarkovModel as bw
import tools
import time

# SCRIPT CONSTANTS

#main input file
nMainFile="SequencesBrutes.txt"
#corrections in the second row
nCorrect="Corrections.txt"
#save file for final results
nSave="AnalysisMCPCond.txt"
# maximum order of a Markov chain
nOrder=24
# number of words drawn randomly
nMaxRP=10000
# confidence level for CI
confidence=0.95


paramTau=[0.1,0.2,0.3]
nTau=len(paramTau)


hm=pickle.load(open("ComputeBICMuriqui.txt","rb"))

# COMPILING FILES

corpus,alphabet=tools.compile(nMainFile,nCorrect)
sizeCorpus=len(corpus)
aR=dict()
for i in range(len(alphabet)):
	aR[alphabet[i]]=i


# RETRIEVE BEST ORDER ACCORDING TO THE BIC
BIC=np.full((len(hm),len(hm[0])),0.0,dtype='float')
for i,s in enumerate(hm):
	for j,hmm in enumerate(s):
		BIC[i][j]=hmm.bicScore(corpus)
bestBIC=np.argmax(np.max(BIC,axis=1))
lMax=hm[bestBIC]
order=lMax[0].n
bestHMM=hm[bestBIC][np.argmax(BIC[bestBIC])]

#Initializing the automata
autoRP=tools.appRPStar(aR)
autoInc=tools.appAutNInc(aR)

# COMPUTE NUMBER OF SEQUENCES FROM EACH PATTERN FROM THE ORIGINAL CORPUS
nRPOriginal=np.array([tools.countPatterns(corpus,autoRP,tau) for tau in paramTau])
nIncOriginal=np.array([tools.countPatterns(corpus,autoInc,tau) for tau in paramTau])
nRPNotIncOrginal=nRPOriginal-nIncOriginal

#Initializing the automata
autoRP=tools.appRPStar(aR)
autoInc=tools.appAutNInc(aR)

# MAIN COMPUTATION

#resInc contains for each value of tau, whether a randomly generated word by the Markov chain is an increasing sequence
resInc=[[] for i in range(nTau)]
#resRP contains for each value of tau, whether a randomly generated word by the Markov chain is an (rp+)+ sequence
resRP=[[] for i in range(nTau)]

timestampInit=time.time()
for i,tau in enumerate(paramTau):
	nRP=0
	while nRP<nMaxRP:
		word=bestHMM.gen()
		l=len(word)
		resInc[i].append(autoInc.distToPat(word)<tau*l)
		if autoRP.distToPat(word)<tau*l:
			resRP[i].append(True) 
			nRP+=1
		else:
			resRP[i].append(False)
		print("Num RP %d (tau=%f): word "%(nRP,tau)+word)
		
timeFinal=time.time()-timestampInit

# EXPLOITATIONS OF THE RESULTS

#Put each array in the form of a boolean array
for i,tau in enumerate(paramTau):
	resRP[i]=np.array(resRP[i],dtype='bool')
	resInc[i]=np.array(resInc[i],dtype='bool')


# Confidence interval:
# Bienayme Chebychev
# P(|X-EX|>l/2)<4sigma²/l²
# For a confidence level of 1-alpha, the length of the confidence interval is:
# l=2sigma/sqrt(alpha)

# RP is Bernoulli: confidence interval length is 2*sqrt(p(1-p))/(sqrt(n)*sqrt(alpha))

# Compute probability of being an (rp+)+ sequence and the length of the confidence interval
pRP=np.full(len(paramTau),0.0)
icRP=np.full(len(paramTau),0.0)
for i,tau in enumerate(paramTau):
	mean=np.mean(resRP[i])
	pRP[i]=mean
	icRP[i]=(2*sqrt(mean*(1-mean)/(len(pRP)*sqrt(1-confidence))))

# Compute probability of being an increasing (rp+)+ given that the sequence is (rp+)+
pIncKRP=np.full(len(paramTau),0.0)
icIncKRP=np.full(len(paramTau),0.0)
for i,tau in enumerate(paramTau):
	indices=resRP[i]
	mean=np.mean(resInc[i][indices])
	pIncKRP[i]=mean
	icIncKRP[i]=(2*sqrt(mean*(1-mean)/(nMaxRP*sqrt(1-confidence))))

# Compute the number of standard deviation away the corpus is from the sequences generated by the HMM (knowing that we generated this much nRP)
nDev=np.full(len(paramTau),0.0)
pDevBinomial=np.full_like(nDev,0.0)
for i,tau in enumerate(paramTau):
	expectancy=nRPOriginal[i]*pIncKRP[i]
	distToExp=abs(nIncOriginal[i]-expectancy)
	nDev[i]=distToExp/(sqrt(nRPOriginal[i]*pIncKRP[i]*(1-pIncKRP[i])))
	pDevBinomial[i]=1-(stats.binom.cdf(expectancy+distToExp,nRPOriginal[i],pIncKRP[i])-stats.binom.cdf(expectancy-distToExp,nRPOriginal[i],pIncKRP[i]))	
pDevBT=1/(nDev*nDev)


	
d={'nDev':nDev,"pDevBT":pDevBT,"pDevBinomial":pDevBinomial,"pIncKRP":pIncKRP,"icIncKRP":icIncKRP,"pRP":pRP,"icRP":icRP,"resRP":resRP,"resInc":resInc}
pickle.dump(d,open(nSave,"wb"))